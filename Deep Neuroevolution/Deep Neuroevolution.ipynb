{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/deep_ga.png\" align=right width=50%></img>\n",
    "# Deep Neuroevolution\n",
    "Author: Jin Yeom (jinyeom@utexas.edu)\n",
    "\n",
    "## Contents\n",
    "- [Configuration](#Configuration)\n",
    "- [Environment](#Environment)\n",
    "- [Genotype](#Genotype)\n",
    "- [Phenotype](#Phenotype)\n",
    "- [Genetic Algorithm (GA)](#Genetic-Algorithm-%28GA%29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import gym\n",
    "from gym import ObservationWrapper\n",
    "from gym.spaces.box import Box\n",
    "from baselines.common import atari_wrappers\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision.transforms import functional as T\n",
    "from torchsummary import summary\n",
    "from deap import creator, base, tools\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE = cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE =\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard deviation for adding noise each mutation\n",
    "SIGMA = 0.005\n",
    "# environment name\n",
    "ENV_NAME = \"PongNoFrameskip-v4\"\n",
    "# environment seed\n",
    "ENV_SEED = 42\n",
    "# observation screen size\n",
    "SCREEN_SIZE = 84\n",
    "# number of channels (stacked frames)\n",
    "N_CHAN = 4\n",
    "# maximum iterations during evaluation\n",
    "MAX_ITER = 5000\n",
    "# number of generations during evolution\n",
    "N_GEN = 1000\n",
    "# population size\n",
    "POP_SIZE = 1000\n",
    "# number of selected individuals each generation\n",
    "N_SEL = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchWrapper(ObservationWrapper):\n",
    "    r\"\"\"ObservationWrapper that outputs observation with the shape of (channels, height, width).\n",
    "    NOTE: adopted from https://github.com/ikostrikov/pytorch-a2c-ppo-acktr.\n",
    "    \"\"\"\n",
    "    def __init__(self, env=None):\n",
    "        super(TorchWrapper, self).__init__(env)\n",
    "        obs_shape = self.observation_space.shape\n",
    "        self.observation_space = Box(self.observation_space.low[0, 0, 0],\n",
    "                                     self.observation_space.high[0, 0, 0],\n",
    "                                     [obs_shape[2], obs_shape[1], obs_shape[0]],\n",
    "                                     dtype=self.observation_space.dtype)\n",
    "\n",
    "    def observation(self, x):\n",
    "        x = x.transpose(2, 0, 1)\n",
    "        return torch.tensor(x, dtype=torch.float, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_atari(env_id):\n",
    "    env = atari_wrappers.make_atari(env_id)\n",
    "    env = atari_wrappers.wrap_deepmind(env)\n",
    "    env = TorchWrapper(env)\n",
    "    env.seed(ENV_SEED)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(state, obs_mean):\n",
    "    display.clear_output(wait=True)\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    ax1.axis(\"off\")\n",
    "    ax1.set_title(\"State\")\n",
    "    ax1.imshow(state)\n",
    "    ax2.axis(\"off\")\n",
    "    ax2.set_title(\"Observation (mean)\")\n",
    "    ax2.imshow(obs_mean)\n",
    "    plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = make_atari(ENV_NAME)\n",
    "stacked_frames = [env.reset() for _ in range(4)]\n",
    "\n",
    "t = done = 0\n",
    "while not done:\n",
    "    if t % 10 == 0:\n",
    "        state = env.render(\"rgb_array\")\n",
    "        obs_mean = sum(stacked_frames).squeeze()\n",
    "        render(state, obs_mean)\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    stacked_frames.pop(0)\n",
    "    stacked_frames.append(obs)\n",
    "    t += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_seed():\n",
    "    return random.randint(0, 2**31-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(ind):\n",
    "    ind.append(rand_seed())\n",
    "    return deepcopy(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(genotype, model, sigma):\n",
    "    # NOTE: making a copy of the template model only makes sense in parallel settings\n",
    "    # model = deepcopy(model)\n",
    "    init_seed, mut_seeds = genotype[0], genotype[1:]\n",
    "    # initialize the model using initialization seed\n",
    "    torch.manual_seed(init_seed)\n",
    "    def init_weights(m):\n",
    "        if type(m) in {nn.Conv2d, nn.Linear}:\n",
    "            torch.nn.init.xavier_normal_(m.weight)\n",
    "    model.apply(init_weights)\n",
    "    # mutate the model using mutation seeds\n",
    "    for seed in mut_seeds:\n",
    "        torch.manual_seed(seed)\n",
    "        for param in model.parameters():\n",
    "            param.data.add_(torch.randn_like(param) * sigma)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ooh, looks like we're going to have to implement the phenotype before testing `decode`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NatureDQN(nn.Module):\n",
    "    def __init__(self, in_channels=4, act_dim=18):\n",
    "        super(NatureDQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=8, stride=4)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
    "        self.fc4 = nn.Linear(7 * 7 * 64, 512)\n",
    "        self.fc5 = nn.Linear(512, act_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc4(x))\n",
    "        return F.softmax(self.fc5(x), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at the network. Remember, `TMPL_MODEL` below will be used to decode each individual genotype during evolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 20, 20]           8,224\n",
      "            Conv2d-2             [-1, 64, 9, 9]          32,832\n",
      "            Conv2d-3             [-1, 64, 7, 7]          36,928\n",
      "            Linear-4                  [-1, 512]       1,606,144\n",
      "            Linear-5                   [-1, 18]           9,234\n",
      "================================================================\n",
      "Total params: 1,693,362\n",
      "Trainable params: 1,693,362\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "TMPL_MODEL = NatureDQN().to(DEVICE)\n",
    "summary(TMPL_MODEL, (4, SCREEN_SIZE, SCREEN_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the genotype and the phenotype both ready, we can write an `evaluate` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ind):\n",
    "    policy = decode(ind, TMPL_MODEL, SIGMA)\n",
    "    policy.eval()\n",
    "    \n",
    "    env = make_atari(ENV_NAME)\n",
    "    stacked_frames = [env.reset() for _ in range(4)]\n",
    "    t = done = fitness = 0\n",
    "    while not done and t < MAX_ITER:\n",
    "        obs = torch.cat(stacked_frames, dim=0).unsqueeze(0)\n",
    "        act_probs = policy(obs)\n",
    "        action = torch.argmax(act_probs)\n",
    "        next_frame, reward, done, _ = env.step(action)\n",
    "        stacked_frames.pop(0) # remove the first frame\n",
    "        stacked_frames.append(next_frame) # add the next frame\n",
    "        fitness += reward\n",
    "        t += 1\n",
    "    return fitness,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Algorithm (GA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jin/anaconda3/envs/research/lib/python3.6/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n",
      "/home/jin/anaconda3/envs/research/lib/python3.6/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, rand_seed, n=1)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"mutate\", mutate)\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "toolbox.register(\"select\", tools.selBest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats.register(\"mean\", np.mean)\n",
    "stats.register(\"std\", np.std)\n",
    "stats.register(\"max\", np.max)\n",
    "\n",
    "elite = tools.HallOfFame(1)\n",
    "logbook = tools.Logbook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b00c8b30a44fdba05ddd186a532f3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='gen.', max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 14 is out of bounds for axis 0 with size 6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-f993e45ae6ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0minvalid_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpopulation\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfitnesses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvalid_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitnesses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-513dde826efd>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(ind)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mact_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mnext_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mstacked_frames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# remove the first frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mstacked_frames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_frame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# add the next frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mObservationWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mObservationWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python/baselines/baselines/common/atari_wrappers.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, ac)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mEpisodicLifeEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python/baselines/baselines/common/atari_wrappers.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwas_real_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# check current lives, make loss of life terminal,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python/baselines/baselines/common/atari_wrappers.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_skip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_skip\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obs_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_skip\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obs_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python/baselines/baselines/common/atari_wrappers.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, ac)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mFireResetEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.6/site-packages/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_episode_started_at\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.6/site-packages/gym/envs/atari/atari_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, a)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_action_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframeskip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 14 is out of bounds for axis 0 with size 6"
     ]
    }
   ],
   "source": [
    "population = toolbox.population(POP_SIZE)\n",
    "for gen in tqdm(range(N_GEN), desc=\"gen.\"):\n",
    "    # evaluate the population\n",
    "    invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "        \n",
    "    # update hall of fame and record evaluations\n",
    "    hof.update(population)\n",
    "    record = stats.compile(population)\n",
    "    logbook.record(gen=gen, evals=len(invalid_ind), **record)\n",
    "    \n",
    "    # selection and mutation to update population\n",
    "    elite = deepcopy(hof[0]) # updated elite after evaluation\n",
    "    selected = toolbox.select(population, k=N_SEL)\n",
    "    offsprings = [toolbox.mutate(random.choice(selected)) for _ in range(POP_SIZE - 1)]\n",
    "    population = offsprings + [elite]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (research)",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
