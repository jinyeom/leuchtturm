{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/deep_ga.png\" align=right width=50%></img>\n",
    "# Deep Neuroevolution\n",
    "Author: Jin Yeom (jinyeom@utexas.edu)\n",
    "\n",
    "## Contents\n",
    "- [Configuration](#Configuration)\n",
    "- [Genotype](#Genotype)\n",
    "- [Phenotype](#Phenotype)\n",
    "- [Environment](#Environment)\n",
    "- [Genetic Algorithm (GA)](#Genetic-Algorithm-%28GA%29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import gym\n",
    "from gym import ObservationWrapper\n",
    "from gym.spaces.box import Box\n",
    "from baselines.common import atari_wrappers\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision.transforms import functional as T\n",
    "from torchsummary import summary\n",
    "from deap import creator, base, tools\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE = cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE =\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGMA = 0.005\n",
    "ENV_NAME = \"PongNoFrameskip-v4\"\n",
    "ENV_SEED = 42\n",
    "SCREEN_SIZE = 84\n",
    "MAX_ITER = 500\n",
    "N_GEN = 1000\n",
    "POP_SIZE = 1000\n",
    "N_SEL = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_seed():\n",
    "    return random.randint(0, 2**31-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(ind):\n",
    "    ind.append(rand_seed())\n",
    "    return ind,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(genotype, tmpl_model, sigma):\n",
    "    model = deepcopy(tmpl_model)\n",
    "    for seed in genotype:\n",
    "        # NOTE: in the paper, the first seed is used for initialization,\n",
    "        # but in such case, every individual in the first generation is\n",
    "        # initialized around zero; we probably don't want that.\n",
    "        #\n",
    "        # Instead, we're going to assume that all individuals are already\n",
    "        # initialized with a better initialization method, e.g., Xavier.\n",
    "        torch.manual_seed(seed)\n",
    "        for param in model.parameters():\n",
    "            param.data.add_(torch.randn_like(param) * sigma)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ooh, looks like we're going to have to implement the phenotype before testing `deocde`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NatureDQN(nn.Module):\n",
    "    def __init__(self, in_channels=4, act_dim=18):\n",
    "        super(NatureDQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=8, stride=4)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
    "        self.fc4 = nn.Linear(7 * 7 * 64, 512)\n",
    "        self.fc5 = nn.Linear(512, act_dim)\n",
    "        \n",
    "        def init_weights(m):\n",
    "            if type(m) in {nn.Conv2d, nn.Linear}:\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "        self.apply(init_weights)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc4(x))\n",
    "        return F.softmax(self.fc5(x), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at the network. Remember, `tmpl_model` below will be used to decode each individual genotype during evolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 20, 20]           8,224\n",
      "            Conv2d-2             [-1, 64, 9, 9]          32,832\n",
      "            Conv2d-3             [-1, 64, 7, 7]          36,928\n",
      "            Linear-4                  [-1, 512]       1,606,144\n",
      "            Linear-5                   [-1, 18]           9,234\n",
      "================================================================\n",
      "Total params: 1,693,362\n",
      "Trainable params: 1,693,362\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "TMPL_MODEL = NatureDQN().to(DEVICE)\n",
    "summary(TMPL_MODEL, (4, SCREEN_SIZE, SCREEN_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchWrapper(ObservationWrapper):\n",
    "    r\"\"\"ObservationWrapper that outputs observation with the shape of (channels, height, width).\n",
    "    NOTE: adopted from https://github.com/ikostrikov/pytorch-a2c-ppo-acktr.\n",
    "    \"\"\"\n",
    "    def __init__(self, env=None):\n",
    "        super(TorchWrapper, self).__init__(env)\n",
    "        obs_shape = self.observation_space.shape\n",
    "        self.observation_space = Box(self.observation_space.low[0, 0, 0],\n",
    "                                     self.observation_space.high[0, 0, 0],\n",
    "                                     [obs_shape[2], obs_shape[1], obs_shape[0]],\n",
    "                                     dtype=self.observation_space.dtype)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        return observation.transpose(2, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(env, t):\n",
    "    display.clear_output(wait=True)\n",
    "    plt.figure()\n",
    "    plt.clf()\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"t = {t}\")\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_atari(env_id):\n",
    "    env = atari_wrappers.make_atari(env_id)\n",
    "    env = atari_wrappers.wrap_deepmind(env)\n",
    "    env = TorchWrapper(env)\n",
    "    env.seed(ENV_SEED)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = make_atari(ENV_NAME)\n",
    "obs = env.reset()\n",
    "\n",
    "t = done = 0\n",
    "while not done:\n",
    "    if t % 10 == 0:\n",
    "        render(env, t)\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ind):\n",
    "    env = gym.make(ENV_NAME).unwrapped\n",
    "    policy = decode(ind, TMPL_MODEL, SIGMA)\n",
    "    policy.eval()\n",
    "    \n",
    "    obs = render(env)\n",
    "    i = done = fitness = 0\n",
    "    while not done and i < MAX_ITER:\n",
    "        act_probs = policy(obs)\n",
    "        action = torch.argmax(act_probs)\n",
    "        _, reward, done, _ = env.step(action)\n",
    "        obs = render(env)\n",
    "        fitness += reward\n",
    "        i += 1\n",
    "    return fitness,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Algorithm (GA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jin/anaconda3/envs/research/lib/python3.6/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n",
      "/home/jin/anaconda3/envs/research/lib/python3.6/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"individual\", tools.initRepeat, list, rand_seed, n=1)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"mutate\", mutate)\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "toolbox.register(\"select\", tools.selBest, k=N_SEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (research)",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
