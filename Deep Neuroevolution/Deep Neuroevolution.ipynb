{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/deep_ga.png\" align=right width=50%></img>\n",
    "# Deep Neuroevolution\n",
    "Author: Jin Yeom (jinyeom@utexas.edu)\n",
    "\n",
    "## Contents\n",
    "- [Configuration](#Configuration)\n",
    "- [Environment](#Environment)\n",
    "- [Genotype](#Genotype)\n",
    "- [Phenotype](#Phenotype)\n",
    "- [Genetic Algorithm (GA)](#Genetic-Algorithm-%28GA%29)\n",
    "- [Genetic Algorithm with Novelty Search (GA-NS)](#Genetic-Algorithm--with-Novelty-Search%28GA-NS%29)\n",
    "- [References](#References)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import gym\n",
    "from gym import ObservationWrapper\n",
    "from gym.spaces.box import Box\n",
    "from baselines.common import atari_wrappers\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision.transforms import functional as T\n",
    "from torchsummary import summary\n",
    "from deap import creator, base, tools\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE = cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE =\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard deviation for adding noise each mutation\n",
    "SIGMA = 0.005\n",
    "# environment name\n",
    "ENV_NAME = \"PongNoFrameskip-v4\"\n",
    "# environment seed\n",
    "ENV_SEED = 42\n",
    "# observation screen size\n",
    "SCREEN_SIZE = 84\n",
    "# number of channels (stacked frames)\n",
    "N_CHAN = 4\n",
    "# maximum iterations during evaluation\n",
    "MAX_ITER = 5000\n",
    "# number of generations during evolution\n",
    "N_GEN = 1000\n",
    "# population size\n",
    "POP_SIZE = 1000\n",
    "# number of selected individuals each generation\n",
    "N_SEL = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchWrapper(ObservationWrapper):\n",
    "    r\"\"\"ObservationWrapper that outputs observation with the shape of (channels, height, width).\n",
    "    NOTE: adopted from https://github.com/ikostrikov/pytorch-a2c-ppo-acktr.\n",
    "    \"\"\"\n",
    "    def __init__(self, env=None):\n",
    "        super(TorchWrapper, self).__init__(env)\n",
    "        obs_shape = self.observation_space.shape\n",
    "        self.observation_space = Box(self.observation_space.low[0, 0, 0],\n",
    "                                     self.observation_space.high[0, 0, 0],\n",
    "                                     [obs_shape[2], obs_shape[1], obs_shape[0]],\n",
    "                                     dtype=self.observation_space.dtype)\n",
    "\n",
    "    def observation(self, x):\n",
    "        x = x.transpose(2, 0, 1)\n",
    "        return torch.tensor(x, dtype=torch.float, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_atari(env_id):\n",
    "    env = atari_wrappers.make_atari(env_id)\n",
    "    env = atari_wrappers.wrap_deepmind(env)\n",
    "    env = TorchWrapper(env)\n",
    "    env.seed(ENV_SEED)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(state, obs_mean):\n",
    "    display.clear_output(wait=True)\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    ax1.axis(\"off\")\n",
    "    ax1.set_title(\"State\")\n",
    "    ax1.imshow(state)\n",
    "    ax2.axis(\"off\")\n",
    "    ax2.set_title(\"Observation (mean)\")\n",
    "    ax2.imshow(obs_mean)\n",
    "    plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD3CAYAAAAT+Z8iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAEN5JREFUeJzt3XmwnXV9x/HP597cbIQk5MYqm4lFQUULDDuFUmtRGepIWarUKHRTZKR0hFbBTgfogMsoI11hGJ1iU1YFZSogVKFUEqCIgsRUMUCMiUD2fbnLt3/8ngMnl5u7hHuW+837NZM5y7P9ziN+zvd8n+c+jyNCAIC8Olo9AABAYxH0AJAcQQ8AyRH0AJAcQQ8AyRH0AJAcQQ8AyRH0LWT7RNsLbK+3vcb2w7aPtn2e7R+MYj1zbYftCY0cL4DxiWBoEdvTJf2npE9Iuk3SREknSdreynEByIeKvnUOlqSIuDki+iJia0TcJ6lH0nWSjre9yfY6SbJ9mu0f2d5ge5nty+vW9VD1uK5a5vhqmT+1vdj2WtvftT2neR8PQLsg6Fvn55L6bN9o+1Tb+0hSRCyWdL6khRExLSJmVvNvlvRRSTMlnSbpE7ZPr6b9TvU4s1pmoe0PSLpM0hmSXifpfyTd3JRPBqCtEPQtEhEbJJ0oKSTdIGml7btsv34X8z8YET+JiP6IeEoltE8eYhPnS/pcRCyOiF5JV0s6nKoe2PMQ9C1UhfB5EXGApHdI2k/SVwab1/axth+wvdL2epUgnz3E6udIutb2uqr9s0aSJe0/tp8CQLsj6NtERPyfpH9TCfzBLil6k6S7JB0YETNU+viuLT7I/MskfTwiZtb9mxIRC8Z+9ADaGUHfIrbfavti2wdUrw+UdI6kRyS9KOkA2xPrFtlb0pqI2Gb7GEl/XDdtpaR+Sb9Z9951ki61fWi1/hm2z27cJwLQrgj61tko6VhJj9rerBLwT0u6WNL3JS2S9ILtVdX8F0i60vZGSX+nckqmJCkitki6StLDVavmuIi4U9IXJN1ie0O17lOb89EAtBNz4xEAyI2KHgCSI+gBIDmCHgCSI+gBIDmCHgCSa4urV9oe8tSfr7xvn2YNBUlddM8aDz8XkFNbBP1YBvkpJxw/qvnvX7BwTJbdUz3+qdNGPO9R13yngSMBsCu0bgAgOYIeAJIj6AEgubbo0Y+l4frmo+nDD1zXaHv4e6KBffjR9PABNAYVPQAkR9ADQHIEPZCA7cttz2/1OEbL9j22z23Qut9r+1uNWPdrYfubtpt6yfB0PXr66MjI9nkq9yo4SNIGSXdKujQi1rVyXKNh+3JJb46IebX3IqKRgXeVpE82cP276wuS/lXSPc3aIBU90OZsX6wSDn8taYak41TuCXz/gLuQNXoc46YwtH20pBkR8UirxzJQRDwmabrto5q1TYIeaGO2p0u6QtKFEXFvRPRExPOS/kjSXEnz6mafbPtW2xttP2H7sLr1fNr28mraz2y/u3q/w/ZnbC+xvdr2bbZnVdPm2g7bf2b7l5K+X7VadqqSbT9p+4zq+bW2l9neYPuHtk+q3n+fpMskfdD2JttPVu8/aPvP68byt7aX2n7J9tdtzxgwlnNt/9L2KtufHWLXnSrpvweMM2xfYPuZaj/8ve2DbC+oxntb/Ren7T+w/ePqrm0LbP9W3bTaPtto+6e2/7Bu2nm2f2D7S7bX2n5ukFbNg5KadkrauPmG3l1cpgDj3AmSJku6o/7NiNhk+25Jp0j6WvX2B1TuOzxP0kWSvmX7YJV7CX9S0tERscL2XEmd1TIXSjpd0skq9x7+B0n/XK2n5mRJb1O5L/HZkj4u6Z8kyfbbVX5d1M6r/V9JV0paX43hdttzI+Je21drQOtmgPOqf++S9JKkr1fb+UjdPCdKOkTSwZIes31HRCweZF3vlPTYIO+/V9KRkg6U9ITK/p0nabWkhdXnvtH2ESr79f2SHq/mucv2IRGxXdISSSdJeqHaJ/Ntvzkifl1t51hJN0qaLeljkr5qe/945ZZ+i6vP0hRU9EB7my1pVUT0DjLt19X0mh9GxDciokfSNSpfEMdJ6pM0SdLbbXdFxPMRsaRa5nxJn42IX1UBdrmkswa0aS6PiM0RsVXl2MDhtudU0z4s6Y5qWUXE/IhYHRG9EfHlaruHjPCzfljSNRHxbERsknSppA8NGMsVEbE1Ip6U9KSkwwZbkaSZKvdlHuiLEbEhIhap3Ef5vmp761V65kdU831M0vUR8WhE9EXEjZK2q+xPRcTtEbEiIvoj4lZJz0g6pm47SyPihojoUwn8fSW9vm76xmqMTUHQA+1tlaTZu+iP71tNr1lWexIR/ZJ+JWm/iPiFpL9SCfGXbN9ie79q1jmS7qzaE+tUKs0+7RxK9evdqFK9f6h66xxJ/1GbbvsS24ttr6/WN0M7fxkNZT9JS+teL1XpOtSP5YW651skTdvFutZK2nuQ91+se751kNe19c2RdHFtv1Sf5cBqjLL90bq2zjpJ79DOn/PlcUbElupp/Vj3ltS0A+kEPdDeFqpUkmfUv2l7mkof+nt1bx9YN71D0gGSVkhSRNwUESeqBFioHNyVSoifGhEz6/5NjojldesdeBnxmyWdY/t4lV8ND1TbPEnS36gcP9gnImaqtHC8i/UMtKIaX80bJfVq5zAeqadU2ju7a5mkqwbsl6kRcXP1a+YGlXZYd/U5n9Yrn3Mk3qbyi6Qp0vfohzvdcqgePqdqjh6XPBhbEbHe9hWS/tH2BpVg31/Sv6hU7P9eN/uR1UHRuyT9pcoXxCO2D6mWeVjSNpXKtdajv07SVbbPjYiltl8n6YSI+PYQw7pbpX99paRbq18PUqlSe1V6/RNsf0bS9LrlXpR0iu2OumXq3Szp07bvqdZxdbX+XnvUtxO4W9Ito12ozg0qv3T+S6XXP1XS70p6SNJeKl9aKyXJ9p+oVPSjcbJ2PpDeUFT0QJuLiC+qnLHyJZVz6B9VqTjfXeuNV74t6YMqbYuPSDqj6tdPkvR5lTbPC5J+Q6X/LUnXqnwx3Gd7o6RHVA4kDjWe7SoHh39f0k11k74r6V5JP1dpu2xTXdtH0u3V42rbTwyy6q+pfHE9JOm5avkLhxrLEGN8QtJ620N+liGWf1zSX6gcDF4r6RcqB4oVET+V9GWVX1svqhz4fXik665O/dxUnWbZFH7lIHDrXHvqrDEbBDceaa7xcuMR7jC157H9HkkXRMTprR5LPdvflPTViLi7WdtM37oBsGeKiPsk3dfqcQwUEWc2e5vpKnpgMFT02JPRoweA5Ah6AEiuLVo3q1evbv0gkFp3dzetG+yxOBgLNNApHWfvsojxkYdKkvqmDX8Byk37T6oeh/8RPmFzeZy9aGtZ/6RyyvzKw0Z+ocvuRT3q2jzYVRfyq+2vVe8c+f6atbhHklqyz773wGXDFjEEPdBA/ScfMfxMI7BtVgn4zXP6hp23a131ZbCoGkOnR7xszcwlHeraPLoxZlHbX5vmjnx/zXiu7PN23Wf06AEgOSp6YByY/ZOt1eOrp9XaOi+eMPJDXQfdvmOn18+9v6yjfzKHy3bloG+8ss+eP22yJKlvymBXcmg/BD0wDmzrLv3irfu8+kf4jhm1Fu3IWw3Ys9C6AYDkqOiBcWDTfuVMkPVvpWrH6FHRA0BybVHRz5/3llYPAclddM+aVg9hTE1ZXir8WT97dYXvPqp+7IyKHgCSa4uKHkBz1c7ieRkXiBhW/T6LjvF1GioVPQAkR0UPjENb9y99+OX7v3pa17rSv3/j/T27XH757w18Z3xVqK2w/F31r8bX/qKiB4DkqOiBcWDailLBd24dvjbr3DHg9fbyZ/qzfjTy/7tP2LzrXwPZvby/fpxnfxH0QAMtOWvkl7odmZFfW2XlMQO3PfJl1xzeKalzxPPnNNr9JbXrPqN1AwDJUdEDDfTsmde3eghI75Jh56CiB4DkCHoASI6gB4DkCHoASI6gB4DkOOsGaKDffuqMVg8ByS18w/DzEPRAA0393IxWDwHZvWf4WWjdAEByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByE1o9AADYk/RMK7Hbs1enJGnC1n5N3NDT0G1S0QNAclT0ANBEm/YtsbvxTeX11BUTNPtpKnoAwGtARQ8ATRSlNa/+rp1fNxIVPQAkR0WPtvX4p07b6fVR13ynRSMBxk7vVJfH7h2SpJ61Exu+TSp6AEiOih4Amsh91ZPeUtm7v/HbJOgBoIlqQe8dpaHS0dv4bdK6AYDkqOiBNtXX1aH+rlKLde4ov+87epvwOz+hnqkl6vonlnbJpHWN/QOldkNFDwDJUdEDbapvSqd6p1S12Oby0LGJin539Oxd/ippw5yyP7ufDklS15YmNMgH6K/Opoy9SrO+b1Lj/2KKih4AkqOiB9pUz14d2j6jdgpeqcm6NrVyROPX5NWlJ987uZTTvVPL/tx0wGRJ0vSlPerc3jf4wmPs5dMrq7Nu3ITNUtEDQHJU9ECb6uuyeqf45efYfbWzlaYv3SZJ2jG9q3os+7VnWqf6O8vzRvftJ24oxwemLC/xO2ltNHR7EkEPtK2evaQdM8vziRsI+rFUu6NT96ISsv1d1upDS/jPXFIaHZPX7GjItjt6yzY7t5f/TTuacKYnrRsASI6KHmhTfZOsnmml5dA3kYq+ESZsLW2a/p4OTVpXTnOsXR9+/dxyoHba8lLZd/aMzamtey/bXj2OyepGhKBH2+KyxMDYIOiBNtU/UeqfXPq5MYEuayN19PZrn2fKgdq+6rIT6980SZLU2VN699OWb2/N4MYA//UAQHJU9ECb6toYmrSqNIwnbGn8KXgoar34WYtL/97943/fU9EDQHJU9ECb6uiROra/8hzNNXFjnp1ORQ8AyVHRA21qwrbQxI3l/PnOHeO/T4zWIeiBNtW1JST1V8+5Dj12H60bAEiOih5oU53b+yVX1yzvpXWD3Tfug/6UE47f6fX9Cxa2aCQA0J7GfdCj9ebNf0aSNH/eW1o8kly6Nveqa3OrR4EM6NEDQHIEPQAkR9ADQHL06PGa0ZsH2hsVPQAkR9ADQHIEPQAkR9ADQHIEPQAkR9ADQHIEPQAkR9ADQHIEPQAkN+7/MpbLEgPA0KjoASA5gh4AkiPoASC5cd+jB9rZkrMmtnoIABU9AGRHRQ800LNnXt/qISC9S4adg4oeAJIj6AEgOYIeAJIj6AEgOYIeAJIj6AEgOYIeAJIj6AEgOYIeAJIj6AEgOS6BADRQxxuecavHAFDRA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJOeIaPUYtHr16tYPAql1d3fzh0vYY1HRA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJNcWlykGADQOFT0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJEfQA0ByBD0AJPf/tTlXRk9WrsUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = make_atari(ENV_NAME)\n",
    "stacked_frames = [env.reset() for _ in range(4)]\n",
    "\n",
    "t = done = 0\n",
    "while not done:\n",
    "    if t % 10 == 0:\n",
    "        state = env.render(\"rgb_array\")\n",
    "        obs_mean = sum(stacked_frames).squeeze()\n",
    "        render(state, obs_mean)\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    stacked_frames.pop(0)\n",
    "    stacked_frames.append(obs)\n",
    "    t += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_seed():\n",
    "    return random.randint(0, 2**31-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(ind):\n",
    "    ind.append(rand_seed())\n",
    "    return deepcopy(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(genotype, model, sigma):\n",
    "    # NOTE: making a copy of the template model only makes sense in parallel settings\n",
    "    # model = deepcopy(model)\n",
    "    init_seed, mut_seeds = genotype[0], genotype[1:]\n",
    "    # initialize the model using initialization seed\n",
    "    torch.manual_seed(init_seed)\n",
    "    def init_weights(m):\n",
    "        if type(m) in {nn.Conv2d, nn.Linear}:\n",
    "            torch.nn.init.xavier_normal_(m.weight)\n",
    "    model.apply(init_weights)\n",
    "    # mutate the model using mutation seeds\n",
    "    for seed in mut_seeds:\n",
    "        torch.manual_seed(seed)\n",
    "        for param in model.parameters():\n",
    "            param.data.add_(torch.randn_like(param) * sigma)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ooh, looks like we're going to have to implement the phenotype before testing `decode`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NatureDQN(nn.Module):\n",
    "    def __init__(self, in_channels, act_dim):\n",
    "        super(NatureDQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=8, stride=4)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
    "        self.fc4 = nn.Linear(7 * 7 * 64, 512)\n",
    "        self.fc5 = nn.Linear(512, act_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc4(x))\n",
    "        return F.softmax(self.fc5(x), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at the network. Remember, `TMPL_MODEL` below will be used to decode each individual genotype during evolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 20, 20]           8,224\n",
      "            Conv2d-2             [-1, 64, 9, 9]          32,832\n",
      "            Conv2d-3             [-1, 64, 7, 7]          36,928\n",
      "            Linear-4                  [-1, 512]       1,606,144\n",
      "            Linear-5                    [-1, 6]           3,078\n",
      "================================================================\n",
      "Total params: 1,687,206\n",
      "Trainable params: 1,687,206\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "act_dim = env.action_space.n\n",
    "TMPL_MODEL = NatureDQN(4, act_dim).to(DEVICE)\n",
    "summary(TMPL_MODEL, (4, SCREEN_SIZE, SCREEN_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the genotype and the phenotype both ready, we can write an `evaluate` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ind):\n",
    "    policy = decode(ind, TMPL_MODEL, SIGMA)\n",
    "    policy.eval()\n",
    "    \n",
    "    env = make_atari(ENV_NAME)\n",
    "    stacked_frames = [env.reset() for _ in range(4)]\n",
    "    t = done = fitness = 0\n",
    "    while not done and t < MAX_ITER:\n",
    "        obs = torch.cat(stacked_frames, dim=0).unsqueeze(0)\n",
    "        act_probs = policy(obs)\n",
    "        action = torch.argmax(act_probs)\n",
    "        next_frame, reward, done, _ = env.step(action)\n",
    "        stacked_frames.pop(0) # remove the first frame\n",
    "        stacked_frames.append(next_frame) # add the next frame\n",
    "        fitness += reward\n",
    "        t += 1\n",
    "    return fitness,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Algorithm (GA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, rand_seed, n=1)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"mutate\", mutate)\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "toolbox.register(\"select\", tools.selBest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats.register(\"mean\", np.mean)\n",
    "stats.register(\"std\", np.std)\n",
    "stats.register(\"max\", np.max)\n",
    "\n",
    "elite = tools.HallOfFame(1)\n",
    "logbook = tools.Logbook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05b745f352a44b82aee169819380b611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='gen.', max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-f993e45ae6ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0minvalid_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpopulation\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfitnesses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvalid_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitnesses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-513dde826efd>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(ind)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstacked_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mact_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mnext_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mstacked_frames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# remove the first frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.6/site-packages/torch/functional.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(input, dim, keepdim)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \"\"\"\n\u001b[1;32m    393\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_argmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_argmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "population = toolbox.population(POP_SIZE)\n",
    "for gen in tqdm(range(N_GEN), desc=\"gen.\"):\n",
    "    # evaluate the population\n",
    "    invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "        \n",
    "    # update hall of fame and record evaluations\n",
    "    hof.update(population)\n",
    "    record = stats.compile(population)\n",
    "    logbook.record(gen=gen, evals=len(invalid_ind), **record)\n",
    "    \n",
    "    # selection and mutation to update population\n",
    "    elite = deepcopy(hof[0]) # updated elite after evaluation\n",
    "    selected = toolbox.select(population, k=N_SEL)\n",
    "    offsprings = [toolbox.mutate(random.choice(selected)) for _ in range(POP_SIZE - 1)]\n",
    "    population = offsprings + [elite]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Algorithm with Novelty Search (GA-NS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (research)",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
