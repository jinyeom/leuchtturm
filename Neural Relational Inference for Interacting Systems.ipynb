{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/nri_sm.png\" width=25% align=\"right\"/>\n",
    "# Neural Relational Inference for Interacting Systems\n",
    "Notebook Author: Jin Yeom (jinyeom@utexas.edu)  \n",
    "Original Authors: Thomas Kipf, Ethan Fetaya, Kuan-Chieh Wang, Max Welling, Richard Zemal\n",
    "\n",
    "## Contents\n",
    "- [Configuration](#Configuration)\n",
    "- [Data Generation](#Data-Generation)\n",
    "- [Dataset and Loaders](#Dataset-and-Loaders)\n",
    "- [Graph Neural Network](#Graph-Neural-Network)\n",
    "- [Neural Relational Inference](#Neural-Relational-Inference)\n",
    "- [References](#References)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook attempts to understand [this paper](https://arxiv.org/abs/1802.04687) (Kipf et al., 2018) by implementing the Neural Relational Inference (NRI) algorithm with PyTorch. Note that code for generating data is imported from the paper's [original implementation](https://github.com/hudl/relational-inference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Tuple, Sequence\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation as anime\n",
    "from IPython.display import HTML\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following script below to generate the particle simulation datasets we'll be using.\n",
    "\n",
    "*NOTE: it seems that there is a bug in ipython that doesn't allow display of `stdout` stream immediately, which means there is no way to know how long this process of data generation takes. Until the bug is fixed, I recommend running this script on terminal! Just to provide a bit of estimation, this process (50000 train; 10000 valid; 10000 test; 5 balls) takes at least **3 hours** to generate on a Macbook Pro.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process is interrupted.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mkdir -p datasets/nri/\n",
    "cd datasets/nri/\n",
    "# git clone https://github.com/ethanfetaya/NRI.git # for HTTPS\n",
    "git clone git@github.com:ethanfetaya/NRI.git\n",
    "python NRI/data/generate_dataset.py \\\n",
    "    --simulation=springs \\\n",
    "    --num-train=50000 \\\n",
    "    --num-valid=10000 \\\n",
    "    --num-test=10000 \\\n",
    "    --length=5000 \\\n",
    "    --length-test=10000 \\\n",
    "    --sample-freq=100 \\\n",
    "    --n-balls=5 \\\n",
    "    --seed=42\n",
    "rm -rf NRI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticleDataset(data.Dataset):\n",
    "    def __init__(self, root, mode=\"train\"):\n",
    "        ds_name = os.path.basename(root)\n",
    "        self._dataset = np.load(f\"{root}/loc_{mode}_{ds_name}.npy\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._dataset) # number of samples\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return torch.Tensor(self._dataset[index, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(root, batch_size, num_workers):\n",
    "    train_set = ParticleDataset(root, mode=\"train\")\n",
    "    valid_set = ParticleDataset(root, mode=\"valid\")  \n",
    "    test_set = ParticleDataset(root, mode=\"test\")\n",
    "    \n",
    "    train_loader = data.DataLoader(train_set,\n",
    "                                   batch_size=batch_size,\n",
    "                                   shuffle=True,\n",
    "                                   num_workers=num_workers)\n",
    "    valid_loader = data.DataLoader(valid_set,\n",
    "                                   batch_size=batch_size,\n",
    "                                   shuffle=True,\n",
    "                                   num_workers=num_workers)\n",
    "    test_loader = data.DataLoader(test_set,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=False,\n",
    "                                  num_workers=1)\n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at what each sample looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample(dataset):\n",
    "    sample_idx = np.random.randint(dataset.shape[0])\n",
    "    sample = dataset[sample_idx]\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes(xlim=(-3, 3), ylim=(-3, 3))\n",
    "    ax.set_title(f\"Training sample {sample_idx}\")\n",
    "    scatter, = ax.plot([], [], 'o')\n",
    "\n",
    "    def init():\n",
    "        scatter.set_data([], [])\n",
    "        return scatter,\n",
    "\n",
    "    def animate(i):\n",
    "        scatter.set_data(sample[i, 0], sample[i, 1])\n",
    "        return scatter,\n",
    "\n",
    "    anim = anime.FuncAnimation(fig,\n",
    "                               animate, \n",
    "                               init_func=init,\n",
    "                               frames=sample.shape[0], \n",
    "                               interval=25,\n",
    "                               blit=True)\n",
    "    plt.close() # to prevent `fig` to show\n",
    "    return anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6c8296b32b63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"springs5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (N, T, dims, particles)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0manim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvisualize_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_html5_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "train, valid, test = load_dataset(\"springs5\")\n",
    "print(train.shape) # (N, T, dims, particles)\n",
    "    \n",
    "anim = visualize_sample(train)\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph neural networks (GNN) are a speicalized class of neural networks that operate on graph ($G = (V, E)$) data by passing local messages among nodes. There are variations of message passing methods; in our case, the message passing operator is defined as below,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "v \\rightarrow e &: h^l_{(i, j)} = f^l_{e}([h^l_i, h^l_j]) \\\\\n",
    "e \\rightarrow v &: h^{l + 1}_j = f^l_{v}([\\sum_{i \\in N_j}h^l_{(i, j)}])\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each pair of nodes that are connected by an edge sends a message with an output of some function $f_e$ (e.g., a neural network) given concatenated embeddings of the two nodes. Then for each destination node of each edge, its edge signals are aggregated in a sum that is transformed by another function $f_v$. When there are multiple layers of this operator, a message from a node can reach further than just its neighboring nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node2edge(h, m_in, m_out):\n",
    "    # assuming that the shape of x is (t, f, n),\n",
    "    h_in = torch.matmul(m_in, h)\n",
    "    h_out = torch.matmul(m_out, h)\n",
    "    return torch.cat([h_in, h_out], dim=2)\n",
    "\n",
    "def edge2node(h, m_in):\n",
    "    # since M_in for edges is the transpose of M_in for nodes,\n",
    "    return torch.matmul(m_in.t(), h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerFcNet(nn.Module):\n",
    "    r\"\"\"Two-layered fully connected neural network with dropout and \n",
    "    batch normalization, as described in the NRI paper (Kipf, et al.).\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, hid_features, out_features, dropout_rate=0.5):\n",
    "        super(TwoLayerFcNet, self).__init__()\n",
    "        self.fc0 = nn.Linear(in_features, hid_features, bias=True)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc1 = nn.Linear(hid_features, out_features, bias=False)\n",
    "        self.bn = nn.BatchNorm1d(out_features)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.fc0(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.elu(self.fc1(x))\n",
    "        return self.bn(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two components can now be used for building the NRI model.  \n",
    "\n",
    "*Note that a 1D convolutional neural network can be used instead of a fully-connected network. But we'll get to that later.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Relational Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![model](images/nri.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neural Relational Inference** (NRI) model is quite similar to the variational autoencoder in that it consists of an encoder, sampling and a decoder. The encoder takes node embeddings during time $1, ..., T$ and makes an inference on interaction types of each edge (a matrix with shape of $E \\times I$, where $E$ is the number of edges and $I$ is the number of interaction types), from which a graph structure is determined by sampling; then the decoder iteratively predicts $\\Delta x^t$ given $x^t$, $t = 1, ..., T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_dim: int, \n",
    "                 hid_dim: int, \n",
    "                 out_dim: int):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.f_emb = TwoLayerFcNet(in_dim, hid_dim, hid_dim)\n",
    "        self.f_e1 = TwoLayerFcNet(hid_dim * 2, hid_dim, hid_dim)\n",
    "        self.f_v1 = TwoLayerFcNet(hid_dim, hid_dim, hid_dim)\n",
    "        self.f_e2 = TwoLayerFcNet(hid_dim * 2, hid_dim, hid_dim)\n",
    "        \n",
    "    def forward(self, x, m_in, m_out):\n",
    "        h = self.f_emb(x)\n",
    "        h_e = self.f_e1(node2edge(h_v, m_in, m_out))\n",
    "        h_v = self.f_v1(edge2node(h_e, m_in))\n",
    "        h_e = self.f_e2(node2edge(h_v, m_in, m_out))\n",
    "        return F.softmax(h_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NRI(nn.Module):\n",
    "    def __init__(self):\n",
    "        super()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending with VQ-VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the NRI model attempts to learn discrete representations of graphs, one can imagine a direct extension of the NRI algorithm with [VQ-VAE](https://arxiv.org/abs/1711.00937v2) (Oord, et al.), a simple generative model that learns discrete representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Neural Relational Inference for Interacting Systems, [arXiv:1802.04687v2 \\[stat.ML\\]](https://arxiv.org/abs/1802.04687)\n",
    "- Neural Discrete Representation Learning, [arXiv:1711.00937v2 \\[cs.LG\\]](https://arxiv.org/abs/1711.00937v2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
