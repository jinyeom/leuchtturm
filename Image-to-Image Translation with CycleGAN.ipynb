{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image-to-Image Translation with CycleGAN\n",
    "Author: Jin Yeom (jinyeom@utexas.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CycleGAN](images/cyclegan.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import wget\n",
    "from matplotlib import image as mpimg\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dataset(name: str):\n",
    "    if name not in [\"ae_photos\", \"apple2orange\", \"summer2winter_yosemite\", \"horse2zebra\", \n",
    "                    \"monet2photo\", \"cezanne2photo\", \"ukiyoe2photo\", \"vangogh2photo\", \"maps\", \n",
    "                    \"cityscapes\", \"facades\", \"iphone2dslr_flower\", \"ae_photos\"]:\n",
    "        raise ValueError(\"invalid argument dataset name\")\n",
    "        \n",
    "    if not os.path.exists(\"./datasets\"):\n",
    "        print(\"Datasets directory not found, creating a new directory 'datasets'...\")\n",
    "        os.mkdir(\"./datasets\")\n",
    "    zip_path = \"./datasets/{}.zip\".format(name)\n",
    "    target_dir = \"./datasets/{}/\".format(name)\n",
    "    \n",
    "    url = \"https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/{}.zip\".format(name)\n",
    "    wget.download(url, out=zip_path)\n",
    "    \n",
    "    os.mkdir(target_dir)\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(\"datasets/\")\n",
    "    os.remove(zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets directory not found, creating a new directory 'datasets'...\n"
     ]
    }
   ],
   "source": [
    "# NOTE: only download if you have to!\n",
    "download_dataset(\"apple2orange\")\n",
    "download_dataset(\"horse2zebra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple2orange  horse2zebra\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![model](images/CycleGAN.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_conv_block(input_, \n",
    "                  filters, \n",
    "                  kernel_size, \n",
    "                  strides, \n",
    "                  activation=None, \n",
    "                  normalize=True, \n",
    "                  name=\"conv_block\"):\n",
    "    \"\"\" 2D convolution layer with options for instance normalization \n",
    "    and activation functions. \"\"\"\n",
    "    with tf.variable_scope(name):\n",
    "        c = conv2d(input_, \n",
    "                   filters, \n",
    "                   kernel_size, \n",
    "                   strides=strides, \n",
    "                   padding=\"valid\",\n",
    "                   kernel_initializer=truncated_normal(stddev=0.02))\n",
    "        if normalize:\n",
    "            c = tf_instance_norm(c)\n",
    "        if activation is not None:\n",
    "            c = activation(c)\n",
    "        return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_deconv_block(input_, \n",
    "                    filters, \n",
    "                    kernel_size, \n",
    "                    strides, \n",
    "                    activation=None, \n",
    "                    normalize=True, \n",
    "                    name=\"deconv_block\"):\n",
    "    \"\"\" 2D transpose convolution layer with options for instance normalization \n",
    "    and activation functions. \"\"\"\n",
    "    with tf.variable_scope(name):\n",
    "        d = conv2d_transpose(input_, \n",
    "                             filters, \n",
    "                             kernel_size, \n",
    "                             strides=strides, \n",
    "                             padding=\"valid\",\n",
    "                             kernel_initializer=truncated_normal(stddev=0.02))\n",
    "        if normalize:\n",
    "            d = tf_instance_norm(d)\n",
    "        if activation is not None:\n",
    "            d = activation(d)\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride):\n",
    "        super().__init__()\n",
    "        self.pad = torch.nn.ReflectionPad2d((kernel_size - 1) // 2)\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride)\n",
    "        self.norm1 = torch.nn.InstanceNorm2d(out_channels)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.conv2 = torch.nn.Conv2d(out_channels, out_channels, kernel_size, stride)\n",
    "        self.norm2 = torch.nn.InstanceNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.pad(x)\n",
    "        z = self.conv1(z)\n",
    "        z = self.norm1(x)\n",
    "        z = self.relu(z)\n",
    "        z = self.pad(z)\n",
    "        z = self.conv2(z)\n",
    "        z = self.norm2(z)\n",
    "        return x + z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we define the architecture of the generator network. Note that the generator network's architecture in CycleGAN is somewhat different from what we're familiar with. Rather than decoding a random Gaussian noise to an image, this generator adopts the mechanism of an image transformation network, which is often used in applications like style transfer and super-resolution. In the origianl paper, 6 residual blocks were used for 128 x 128 images, and 9 for 256 x 256 images. We're going to assume the latter for now, but this can change in the future, based on the desired resolution of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(input_, name=\"generator\"):\n",
    "    with tf.variable_scope(name):\n",
    "        with tf.name_scope(\"encoder\"):\n",
    "            e_0 = tf.pad(input_, [[0, 0], [3, 3], [3, 3], [0, 0]], \"reflect\")\n",
    "            e_0 = tf_conv_block(c_0, 32, 7, 1, activation=relu, name=\"e_0\")\n",
    "            e_1 = tf_conv_block(c_0, 64, 3, 2, activation=relu, name=\"e_1\")\n",
    "            e_2 = tf_conv_block(c_1, 128, 3, 2, activation=relu, name=\"e_2\")\n",
    "        with tf.name_scope(\"transformer\"):\n",
    "            r_0 = tf_residual_block(e_2, 128, 3, 1, name=\"r_0\")\n",
    "            r_1 = tf_residual_block(r_0, 128, 3, 1, name=\"r_1\")\n",
    "            r_2 = tf_residual_block(r_1, 128, 3, 1, name=\"r_2\")\n",
    "            r_3 = tf_residual_block(r_2, 128, 3, 1, name=\"r_3\")\n",
    "            r_4 = tf_residual_block(r_3, 128, 3, 1, name=\"r_4\")\n",
    "            r_5 = tf_residual_block(r_4, 128, 3, 1, name=\"r_5\")\n",
    "            r_6 = tf_residual_block(r_5, 128, 3, 1, name=\"r_6\")\n",
    "            r_7 = tf_residual_block(r_6, 128, 3, 1, name=\"r_7\")\n",
    "            r_8 = tf_residual_block(r_7, 128, 3, 1, name=\"r_8\")\n",
    "        with tf.name_scope(\"decoder\"):\n",
    "            d_0 = tf_deconv_block(r_8, 64, 3, 2, activation=relu, name=\"d_0\")\n",
    "            d_1 = tf_deconv_block(d_0, 32, 3, 2, activation=relu, name=\"d_1\")\n",
    "            d_1 = tf.pad(d_1, [[0, 0], [3, 3], [3, 3], [0, 0]], \"reflect\")\n",
    "            pred = tf_conv_block(d_1, 3, 7, 1, activation=tanh, normalize=False, name=\"pred\")\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        self.pad = torch.nn.ReflectionPad2d(3)\n",
    "        self.encoder = torch.nn.Sequential(torch.nn.Conv2d(in_channel, 32, 7, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriminator network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section describes the descriminator network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def descriminator(input_, name):\n",
    "    with tf.variable_scope(name):\n",
    "        h_0 = tf_conv_block(input_, 64, 7, 2, activation=leaky_relu, normalize=False, name=\"h_0\")\n",
    "        h_1 = tf_conv_block(h_0, 128, 7, 2, activation=leaky_relu, name=\"h_1\")\n",
    "        h_2 = tf_conv_block(h_1, 256, 7, 2, activation=leaky_relu, name=\"h_2\")\n",
    "        h_3 = tf_conv_block(h_2, 512, 7, 2, activation=leaky_relu, name=\"h_3\")\n",
    "        pred = tf_conv_block(h_3, 1, 7, 1, 1, normalize=False, name=\"pred\")\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "1. https://arxiv.org/pdf/1703.10593.pdf (Orignal CycleGAN paper)\n",
    "2. https://arxiv.org/pdf/1603.08155v1.pdf (Perceptual losses and image transformation network)\n",
    "3. https://arxiv.org/pdf/1607.08022.pdf (Instance normalization)\n",
    "4. https://hardikbansal.github.io/CycleGANBlog/ (TensorFlow tutorial for CycleGAN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (research)",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
