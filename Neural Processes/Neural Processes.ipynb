{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/np.png\" width=50% align=right></img>\n",
    "# Neural Processes\n",
    "Author: Jin Yeom (jinyeom@utexas.edu)\n",
    "\n",
    "## Contents\n",
    "- [Introduction](#Introduction)\n",
    "- [1-D Regression](#1-D-Regression)\n",
    "- [Implementation](#Implementation)\n",
    "- [Experiments](#Experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Neural Processes](https://arxiv.org/abs/1807.01622) (NPs) are a novel class of function approximation  methods that was presented by DeepMind, just few months back in July, 2018. Generalizing from their previous work, [Conditional Neural Processes](https://arxiv.org/abs/1807.01613) (CNPs), NPs bring benefits of neural networks and Gaussian processes (GPs), i.e., while being able to estimate the distribution of functions and adapt rapidly to new observations like GPs, they are computationally efficient during training like neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To borrow from DeepMind's [CNP notebook](https://github.com/deepmind/conditional-neural-process/blob/master/conditional_neural_process.ipynb),\n",
    "\n",
    "> [Conditional Neural Processes](https://arxiv.org/pdf/1807.01613.pdf) (CNPs) were introduced as a continuation of [Generative Query Networks](https://deepmind.com/blog/neural-scene-representation-and-rendering/) (GQN) to extend its training regime to tasks beyond scene rendering, e.g. to regression and classification.\n",
    ">\n",
    "> In contrast to most standard neural networks, CNPs learn to approximate a distribution over functions rather than approximating just a single function. As a result, at test time CNPs are flexible and can approximate any function from this distribution when provided with a handful of observations. In addition, they learn to estimate the uncertainty of their prediction from the dataset and as the number of observations is increased this uncertainty reduces and the accuracy of their prediction increases.\n",
    "\n",
    "NPs are simply an extension of CNPs with latent variables that allow global sampling, hence are able to produce different function samples from the same observed context data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NPs consist of three main components:\n",
    "* An **encoder** $h$ which encodes *pairs* of $(x_i, y_i)$ context values to their representations $r_i$ \n",
    "* An **aggregator** $a$ that summarizes encoded context values ($r_1$, $r_2$, ..., $r_n$) to a representation $r$\n",
    "* A **condition decoder** $g$ that takes a sampled $z$ and the new target locations $x_T$ and predicts $y_T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-D Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the purpose of this notebook is to explore the basics of NPs, we'll aim to reproduce the 1-D regression result by Garnelo et al. Once again, this data generaion code is adopted from DeepMind's CNP notebook, to be used with PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The NP takes as input a `CNPRegressionDescription` namedtuple with fields:\n",
    "#   `query`: a tuple containing ((context_x, context_y), target_x)\n",
    "#   `target_y`: a tesor containing the ground truth for the targets to be\n",
    "#     predicted\n",
    "#   `num_total_points`: A vector containing a scalar that describes the total\n",
    "#     number of datapoints used (context + target)\n",
    "#   `num_context_points`: A vector containing a scalar that describes the number\n",
    "#     of datapoints used as context\n",
    "# The GPCurvesReader returns the newly sampled data in this format at each\n",
    "# iteration\n",
    "NPRegressionDescription = collections.namedtuple(\n",
    "        \"NPRegressionDescription\",\n",
    "        (\"query\", \"target_y\", \"num_total_points\", \"num_context_points\"))\n",
    "\n",
    "\n",
    "class GPCurvesReader(object):\n",
    "    \"\"\"Generates curves using a Gaussian Process (GP).\n",
    "\n",
    "    Supports vector inputs (x) and vector outputs (y). Kernel is\n",
    "    mean-squared exponential, using the x-value l2 coordinate distance scaled by\n",
    "    some factor chosen randomly in a range. Outputs are independent gaussian\n",
    "    processes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, batch_size, max_num_context, x_size=1, y_size=1,\n",
    "            l1_scale=0.4, sigma_scale=1.0, testing=False):\n",
    "        \"\"\"Creates a regression dataset of functions sampled from a GP.\n",
    "\n",
    "        Args:\n",
    "            batch_size: An integer.\n",
    "            max_num_context: The max number of observations in the context.\n",
    "            x_size: Integer >= 1 for length of \"x values\" vector.\n",
    "            y_size: Integer >= 1 for length of \"y values\" vector.\n",
    "            l1_scale: Float; typical scale for kernel distance function.\n",
    "            sigma_scale: Float; typical scale for variance.\n",
    "            testing: Boolean that indicates whether we are testing. If so there are\n",
    "                    more targets for visualization.\n",
    "        \"\"\"\n",
    "        self._batch_size = batch_size\n",
    "        self._max_num_context = max_num_context\n",
    "        self._x_size = x_size\n",
    "        self._y_size = y_size\n",
    "        self._l1_scale = l1_scale\n",
    "        self._sigma_scale = sigma_scale\n",
    "        self._testing = testing\n",
    "\n",
    "    def _gaussian_kernel(self, xdata, l1, sigma_f, sigma_noise=2e-2):\n",
    "        \"\"\"Applies the Gaussian kernel to generate curve data.\n",
    "\n",
    "        Args:\n",
    "            xdata: Tensor with shape `[batch_size, num_total_points, x_size]` with\n",
    "                    the values of the x-axis data.\n",
    "            l1: Tensor with shape `[batch_size, y_size, x_size]`, the scale\n",
    "                    parameter of the Gaussian kernel.\n",
    "            sigma_f: Float tensor with shape `[batch_size, y_size]`; the magnitude\n",
    "                    of the std.\n",
    "            sigma_noise: Float, std of the noise that we add for stability.\n",
    "\n",
    "        Returns:\n",
    "            The kernel, a float tensor with shape\n",
    "            `[batch_size, y_size, num_total_points, num_total_points]`.\n",
    "        \"\"\"\n",
    "        num_total_points = xdata.shape[1]\n",
    "\n",
    "        # Expand and take the difference\n",
    "        xdata1 = xdata.unsqueeze(1)  # [B, 1, num_total_points, x_size]\n",
    "        xdata2 = xdata.unsqueeze(2)  # [B, num_total_points, 1, x_size]\n",
    "        diff = xdata1 - xdata2  # [B, num_total_poinst, num_total_points, x_size]\n",
    "\n",
    "        # [B, y_size, num_total_points, num_total_points, x_size]\n",
    "        norm = (diff[:, None, :, :, :] / l1[:, :, None, None, :])**2\n",
    "        norm = torch.sum(norm, -1)  # [B, data_size, num_total_points, num_total_points]\n",
    "\n",
    "        # [B, y_size, num_total_points, num_total_points]\n",
    "        kernel = (sigma_f**2)[:, :, None, None] * torch.exp(-0.5 * norm)\n",
    "\n",
    "        # Add some noise to the diagonal to make the cholesky work.\n",
    "        kernel += (sigma_noise**2) * torch.eye(num_total_points)\n",
    "\n",
    "        return kernel\n",
    "\n",
    "    def generate_curves(self):\n",
    "        \"\"\"Builds the op delivering the data.\n",
    "\n",
    "        Generated functions are `float32` with x values between -2 and 2.\n",
    "    \n",
    "        Returns:\n",
    "            A `NPRegressionDescription` namedtuple.\n",
    "        \"\"\"\n",
    "        num_context = np.random.randint(3, self._max_num_context)\n",
    "\n",
    "        # If we are testing we want to have more targets and have them evenly\n",
    "        # distributed in order to plot the function.\n",
    "        if self._testing:\n",
    "            num_target = 400\n",
    "            num_total_points = num_target\n",
    "            x_values = torch.arange(-2.0, 2.0, 0.01).unsqueeze(0).repeat(self._batch_size, 1)\n",
    "            x_values = x_values.unsqueeze(-1)\n",
    "            \n",
    "        # During training the number of target points and their x-positions are\n",
    "        # selected at random\n",
    "        else:\n",
    "            num_target = np.random.randint(2, self._max_num_context)\n",
    "            num_total_points = num_context + num_target\n",
    "            x_values = 4.0 * torch.rand(self._batch_size, num_total_points, self._x_size) - 2.0\n",
    "\n",
    "        # Set kernel parameters\n",
    "        l1 = torch.ones(self._batch_size, self._y_size, self._x_size) * self._l1_scale\n",
    "        sigma_f = torch.ones(self._batch_size, self._y_size) * self._sigma_scale\n",
    "\n",
    "        # Pass the x_values through the Gaussian kernel\n",
    "        # [batch_size, y_size, num_total_points, num_total_points]\n",
    "        kernel = self._gaussian_kernel(x_values, l1, sigma_f)\n",
    "        \n",
    "        # Calculate Cholesky, using double precision for better stability:\n",
    "        cholesky = torch.cholesky(kernel.double()).float()\n",
    "\n",
    "        # Sample a curve\n",
    "        # [batch_size, y_size, num_total_points, 1]\n",
    "        y_values = torch.matmul(cholesky, torch.randn(self._batch_size, self._y_size, num_total_points, 1))\n",
    "\n",
    "        # [batch_size, num_total_points, y_size]\n",
    "        y_values = y_values.squeeze(3).permute(0, 2, 1)\n",
    "\n",
    "        if self._testing:\n",
    "            # Select the targets\n",
    "            target_x = x_values\n",
    "            target_y = y_values\n",
    "\n",
    "            # Select the observations\n",
    "            idx = torch.randperm(num_target)\n",
    "            context_x = torch.index_select(x_values, 1, idx[:num_context])\n",
    "            context_y = torch.index_select(y_values, 1, idx[:num_context])\n",
    "\n",
    "        else:\n",
    "            # Select the targets which will consist of the context points as well as\n",
    "            # some new target points\n",
    "            target_x = x_values[:, :num_target + num_context, :]\n",
    "            target_y = y_values[:, :num_target + num_context, :]\n",
    "\n",
    "            # Select the observations\n",
    "            context_x = x_values[:, :num_context, :]\n",
    "            context_y = y_values[:, :num_context, :]\n",
    "\n",
    "        query = ((context_x, context_y), target_x)\n",
    "\n",
    "        return NPRegressionDescription(\n",
    "                query=query, \n",
    "                target_y=target_y,\n",
    "                num_total_points=target_x.shape[1], \n",
    "                num_context_points=num_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset\n",
    "dataset_train = GPCurvesReader(batch_size=64, max_num_context=10)\n",
    "data_train = dataset_train.generate_curves()\n",
    "\n",
    "# Test dataset\n",
    "dataset_test = GPCurvesReader(batch_size=1, max_num_context=10, testing=True)\n",
    "data_test = dataset_test.generate_curves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_functions(target_x, target_y, context_x, context_y, pred_y=None, var=None):\n",
    "    \"\"\"Plots the predicted mean and variance and the context points.\n",
    "  \n",
    "    Args: \n",
    "        target_x: An array of shape batchsize x number_targets x 1 that contains the\n",
    "                x values of the target points.\n",
    "        target_y: An array of shape batchsize x number_targets x 1 that contains the\n",
    "                y values of the target points.\n",
    "        context_x: An array of shape batchsize x number_context x 1 that contains \n",
    "                the x values of the context points.\n",
    "        context_y: An array of shape batchsize x number_context x 1 that contains \n",
    "                the y values of the context points.\n",
    "        pred_y: An array of shape batchsize x number_targets x 1  that contains the\n",
    "                predicted means of the y values at the target points in target_x.\n",
    "        pred_y: An array of shape batchsize x number_targets x 1  that contains the\n",
    "                predicted variance of the y values at the target points in target_x.\n",
    "    \"\"\"\n",
    "    # Plot everything\n",
    "    plt.plot(target_x[0], target_y[0], ':', linewidth=2)\n",
    "    plt.plot(context_x[0], context_y[0], 'o', markersize=10)\n",
    "    \n",
    "    if pred_y is not None and var is not None:\n",
    "        plt.plot(target_x[0], pred_y[0], 'b', linewidth=2)\n",
    "        plt.fill_between(\n",
    "                target_x[0, :, 0],\n",
    "                pred_y[0, :, 0] - var[0, :, 0],\n",
    "                pred_y[0, :, 0] + var[0, :, 0],\n",
    "                alpha=0.2,\n",
    "                facecolor='#65c9f7',\n",
    "                interpolate=True)\n",
    "\n",
    "    # Make the plot pretty\n",
    "    plt.yticks([-2, 0, 2], fontsize=16)\n",
    "    plt.xticks([-2, 0, 2], fontsize=16)\n",
    "    plt.ylim([-2, 2])\n",
    "    plt.grid(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "((context_x, context_y), target_x), target_y = data_test.query, data_test.target_y\n",
    "plot_functions(target_x.numpy(), target_y.numpy(), context_x.numpy(), context_y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, cx_size, cy_size, repr_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(cx_size + cy_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 128)\n",
    "        self.fc4 = nn.Linear(128, repr_size)\n",
    "        \n",
    "    def forward(self, context_x, context_y):\n",
    "        input_ = torch.cat((context_x, context_y), dim=-1)\n",
    "        input_ = F.relu(self.fc1(input_), inplace=True)\n",
    "        input_ = F.relu(self.fc2(input_), inplace=True)\n",
    "        input_ = F.relu(self.fc3(input_), inplace=True)\n",
    "        repr_ = self.fc4(input_) # representation\n",
    "        return torch.mean(repr_, 0, keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalDecoder(nn.Module):\n",
    "    def __init__(self, tx_size, repr_size):\n",
    "        super(ConditionalDecoder, self).__init__()\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
